{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Montar drive"
      ],
      "metadata": {
        "id": "czvegK-5r0Yu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGPYu5G9rm5-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## revisar particion de datos"
      ],
      "metadata": {
        "id": "rNgRvvH6Cyeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dir_dataset = '/content/drive/MyDrive/projects/brainTumor/dataset'\n",
        "\n",
        "train_path = 'train'\n",
        "val_path = 'val'\n",
        "\n",
        "train_dir = os.path.join(dir_dataset, train_path)\n",
        "val_dir = os.path.join(dir_dataset, val_path)\n",
        "\n",
        "def count_files_in_subdirectories(base_directory):\n",
        "    \"\"\"\n",
        "    Counts the number of files in each immediate subdirectory\n",
        "    of a given base directory.\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(base_directory):\n",
        "        print(f\"Error: Directory not found at {base_directory}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nCounting files in subdirectories of: {base_directory}\")\n",
        "    total_files = 0\n",
        "    for subdir_name in os.listdir(base_directory):\n",
        "        subdir_path = os.path.join(base_directory, subdir_name)\n",
        "        if os.path.isdir(subdir_path): # Ensure it's a directory\n",
        "            num_files = len([f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))])\n",
        "            print(f\"  {subdir_name}/: {num_files} files\")\n",
        "            total_files += num_files\n",
        "    print(f\"Total files in {base_directory}: {total_files}\")\n",
        "\n",
        "# Contar archivos train\n",
        "count_files_in_subdirectories(train_dir)\n",
        "\n",
        "# Contar archivos validation\n",
        "count_files_in_subdirectories(val_dir)\n",
        "\n",
        "# Para los directorios se usa la regla 80/20\n"
      ],
      "metadata": {
        "id": "IGwH2R3etKcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importar librerias"
      ],
      "metadata": {
        "id": "z5mK_b6_DKTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n"
      ],
      "metadata": {
        "id": "P1fq3qd2CtB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparar datos"
      ],
      "metadata": {
        "id": "kBNBFZjxDVui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constantes de datos de entrada"
      ],
      "metadata": {
        "id": "pR9q43p0FDga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants for EfficientNetB0\n",
        "\n",
        "# images\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32 # EfficientNet is efficient, so we can often use a larger batch size\n",
        "\n",
        "# learning_rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "# epochs\n",
        "epochs = 15\n",
        "\n",
        "# dropout\n",
        "DROPOUT = 0.5\n",
        "\n",
        "# path to model\n",
        "model_save_path = '/content/drive/MyDrive/projects/brainTumor/'\n"
      ],
      "metadata": {
        "id": "5IH0CnyHDaoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# aumentar data de entranamiento"
      ],
      "metadata": {
        "id": "d-pHMLsGFHpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation for Training\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Only preprocessing for Validation\n",
        "validation_image_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    directory=train_dir,\n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary' # Changed to binary\n",
        ")\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    directory=val_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode='binary' # Changed to binary\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjXy2LiDFJV1",
        "outputId": "511a4868-8e46-4bc8-a5b3-dd01e44a774f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3679 images belonging to 2 classes.\n",
            "Found 921 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificar clases"
      ],
      "metadata": {
        "id": "EkdpYLtGKTYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Verificación de Clases e Índices ---\")\n",
        "\n",
        "# Acceder al mapeo de class_indices\n",
        "class_indices = train_data_gen.class_indices\n",
        "print(f\"Mapeo de clases a índices: {class_indices}\")\n",
        "\n",
        "# 2. Obtener los nombres de las clases en el orden de los índices (para predicciones)\n",
        "# Esto es importante porque el modelo predice un índice (0, 1, 2...)\n",
        "# y se necesita saber a qué clase corresponde cada índice.\n",
        "num_classes = len(class_indices)\n",
        "class_names = [None] * num_classes # Crear una lista vacía con el tamaño correcto\n",
        "\n",
        "for class_name, index in class_indices.items():\n",
        "    class_names[index] = class_name\n",
        "\n",
        "print(f\"Nombres de las clases en el orden de los índices del modelo: {class_names}\")"
      ],
      "metadata": {
        "id": "mdoZ1rurKVPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calcular pesos"
      ],
      "metadata": {
        "id": "ySdo2-a7KjZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Calcular los pesos de las clases ---\n",
        "# Para calcular class_weights, necesitamos conocer la distribución de las clases en el conjunto de entrenamiento.\n",
        "# El atributo .classes del generador de datos contiene los índices de clase para cada imagen.\n",
        "# Esto es más preciso que simplemente contar archivos, ya que usa los datos que el generador realmente ve.\n",
        "\n",
        "print(\"\\n--- Calculando pesos de las clases para manejar el desbalance ---\")\n",
        "# Obtener los índices de clase de todas las imágenes en el conjunto de entrenamiento\n",
        "# (esto puede tardar un poco si el dataset es muy grande)\n",
        "labels = train_data_gen.classes\n",
        "\n",
        "# Calcular los pesos de las clases\n",
        "# La función compute_class_weight de sklearn calcula pesos inversamente proporcionales a la frecuencia de la clase.\n",
        "# Las clases con menos muestras tendrán un peso mayor.\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced', # 'balanced' es la opción clave aquí\n",
        "    classes=np.unique(labels), # Asegura que todas las clases estén representadas\n",
        "    y=labels # Las etiquetas de clase de tus datos de entrenamiento\n",
        ")\n",
        "\n",
        "# Convertir el array de pesos a un diccionario, que es el formato que espera Keras\n",
        "class_weights = dict(enumerate(weights))\n",
        "\n",
        "print(f\"Pesos de las clases calculados: {class_weights}\")\n",
        "# Ejemplo de salida: {0: 1.5, 1: 0.7, 2: 1.8}\n",
        "# Donde los índices (0, 1, 2) corresponden a las clases según train_data_gen.class_indices\n",
        "# Y los valores (1.5, 0.7, 1.8) son los pesos. Un peso > 1 significa que es una clase minoritaria\n",
        "# y los errores en ella tendrán mas impacto"
      ],
      "metadata": {
        "id": "v5ermu44KiLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cargar modelo preentrenado EfficientNetB0"
      ],
      "metadata": {
        "id": "COQXrf8gGlav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained EfficientNetB0\n",
        "base_model = EfficientNetB0(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
        "                            include_top=False,\n",
        "                            weights='imagenet')\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build custom head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(DROPOUT)(x)\n",
        "# Binary output: 1 neuron with Sigmoid activation\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n"
      ],
      "metadata": {
        "id": "WsVbg3gIGtwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## compilar modelo"
      ],
      "metadata": {
        "id": "pVlFJnMXLGJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "              loss='binary_crossentropy', # Appropriate for binary\n",
        "              metrics=['accuracy', Precision(name='precision'), Recall(name='recall'), AUC(name='auc')])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "KMSufKuXLIid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir pasos y callbacks"
      ],
      "metadata": {
        "id": "5zYGTX5_IxJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejor modelo\n",
        "log_dir = os.path.join(model_save_path, \"logs\")\n",
        "pathModeloMejorPrecision = os.path.join(model_save_path, 'modeloMejorPrecision.h5')\n",
        "\n",
        "# Calculate steps_per_epoch and validation_steps robustly\n",
        "steps_per_epoch_train = train_data_gen.samples // BATCH_SIZE\n",
        "if train_data_gen.samples % BATCH_SIZE != 0: # Account for partial last batch\n",
        "    steps_per_epoch_train += 1\n",
        "\n",
        "steps_per_epoch_val = val_data_gen.samples // BATCH_SIZE\n",
        "if val_data_gen.samples % BATCH_SIZE != 0: # Account for partial last batch\n",
        "    steps_per_epoch_val += 1\n",
        "\n",
        "# Callbacks para mejorar entrenamiento, principalmente precision\n",
        "callbacks = [\n",
        "    # EarlyStopping: Monitor 'val_precision' and restore best weights\n",
        "    EarlyStopping(monitor='val_precision',\n",
        "                  patience=5, # Increased patience as precision might fluctuate more\n",
        "                  mode='max', # 'max' because we want to maximize precision\n",
        "                  restore_best_weights=True,\n",
        "                  verbose=1),\n",
        "\n",
        "    # ModelCheckpoint: Save the model with the highest 'val_precision'\n",
        "    ModelCheckpoint(filepath=pathModeloMejorPrecision,\n",
        "                    monitor='val_precision',\n",
        "                    save_best_only=True,\n",
        "                    mode='max', # 'max' because we want to maximize precision\n",
        "                    verbose=1),\n",
        "\n",
        "    # Optional: ReduceLROnPlateau can also monitor precision\n",
        "    ReduceLROnPlateau(monitor='val_precision',\n",
        "                      factor=0.2, # Reduce learning rate by 20%\n",
        "                      patience=3, # If val_precision doesn't improve for 3 epochs\n",
        "                      mode='max',\n",
        "                      min_lr=0.00001, # Minimum learning rate\n",
        "                      verbose=1),\n",
        "]\n"
      ],
      "metadata": {
        "id": "9-rsFPjHIzZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar modelo"
      ],
      "metadata": {
        "id": "PmjmWdR3JKP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenar modelo base EfficientNetB0"
      ],
      "metadata": {
        "id": "6R-R5nnxIZ8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Iniciando entrenamiento...\")\n",
        "# cambiar nombre history por history_base\n",
        "# para no confundir con history_fine_tuning\n",
        "history_base = model.fit(\n",
        "    train_data_gen,\n",
        "    # Pasos por epoca train\n",
        "    steps_per_epoch=steps_per_epoch_train,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    # Pasos por epoca validación\n",
        "    validation_steps=steps_per_epoch_val,\n",
        "    class_weight=class_weights, # pesos por clase para evitar desbalance\n",
        "    callbacks=callbacks # Optimiza entrenamiento\n",
        ")\n",
        "print(\"Entrenamiento finalizado.\")\n"
      ],
      "metadata": {
        "id": "vkfdaBzsIZIp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}