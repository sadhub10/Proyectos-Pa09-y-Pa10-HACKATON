{
  "best_global_step": 3164,
  "best_metric": 0.8073234999560651,
  "best_model_checkpoint": "C:\\Users\\Linette\\PycharmProjects\\mental-health-monitoring\\src\\models\\transformers\\checkpoints\\distilbert\\runs\\checkpoint-3164",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 3164,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0316055625790139,
      "grad_norm": 3.915841579437256,
      "learning_rate": 1.9690265486725665e-05,
      "loss": 1.1256,
      "step": 50
    },
    {
      "epoch": 0.0632111251580278,
      "grad_norm": 3.4868032932281494,
      "learning_rate": 1.9374209860935526e-05,
      "loss": 0.9603,
      "step": 100
    },
    {
      "epoch": 0.09481668773704172,
      "grad_norm": 3.634799003601074,
      "learning_rate": 1.9058154235145386e-05,
      "loss": 0.8345,
      "step": 150
    },
    {
      "epoch": 0.1264222503160556,
      "grad_norm": 4.519175052642822,
      "learning_rate": 1.8742098609355247e-05,
      "loss": 0.7559,
      "step": 200
    },
    {
      "epoch": 0.15802781289506954,
      "grad_norm": 11.46041202545166,
      "learning_rate": 1.8426042983565108e-05,
      "loss": 0.7105,
      "step": 250
    },
    {
      "epoch": 0.18963337547408343,
      "grad_norm": 4.9870147705078125,
      "learning_rate": 1.810998735777497e-05,
      "loss": 0.6069,
      "step": 300
    },
    {
      "epoch": 0.22123893805309736,
      "grad_norm": 6.7020263671875,
      "learning_rate": 1.779393173198483e-05,
      "loss": 0.6081,
      "step": 350
    },
    {
      "epoch": 0.2528445006321112,
      "grad_norm": 15.267436981201172,
      "learning_rate": 1.747787610619469e-05,
      "loss": 0.5789,
      "step": 400
    },
    {
      "epoch": 0.28445006321112515,
      "grad_norm": 4.079987525939941,
      "learning_rate": 1.7161820480404552e-05,
      "loss": 0.5991,
      "step": 450
    },
    {
      "epoch": 0.31605562579013907,
      "grad_norm": 3.689913272857666,
      "learning_rate": 1.6845764854614413e-05,
      "loss": 0.5767,
      "step": 500
    },
    {
      "epoch": 0.347661188369153,
      "grad_norm": 4.815955638885498,
      "learning_rate": 1.6529709228824277e-05,
      "loss": 0.5459,
      "step": 550
    },
    {
      "epoch": 0.37926675094816686,
      "grad_norm": 9.454623222351074,
      "learning_rate": 1.6213653603034138e-05,
      "loss": 0.5406,
      "step": 600
    },
    {
      "epoch": 0.4108723135271808,
      "grad_norm": 3.082533359527588,
      "learning_rate": 1.5897597977244e-05,
      "loss": 0.5526,
      "step": 650
    },
    {
      "epoch": 0.4424778761061947,
      "grad_norm": 3.9449241161346436,
      "learning_rate": 1.5581542351453856e-05,
      "loss": 0.512,
      "step": 700
    },
    {
      "epoch": 0.4740834386852086,
      "grad_norm": 6.007071495056152,
      "learning_rate": 1.5265486725663717e-05,
      "loss": 0.533,
      "step": 750
    },
    {
      "epoch": 0.5056890012642224,
      "grad_norm": 8.889245986938477,
      "learning_rate": 1.494943109987358e-05,
      "loss": 0.482,
      "step": 800
    },
    {
      "epoch": 0.5372945638432364,
      "grad_norm": 6.552772045135498,
      "learning_rate": 1.463337547408344e-05,
      "loss": 0.5116,
      "step": 850
    },
    {
      "epoch": 0.5689001264222503,
      "grad_norm": 5.526355266571045,
      "learning_rate": 1.4317319848293301e-05,
      "loss": 0.4998,
      "step": 900
    },
    {
      "epoch": 0.6005056890012642,
      "grad_norm": 9.896169662475586,
      "learning_rate": 1.4001264222503162e-05,
      "loss": 0.5295,
      "step": 950
    },
    {
      "epoch": 0.6321112515802781,
      "grad_norm": 3.9896442890167236,
      "learning_rate": 1.3685208596713021e-05,
      "loss": 0.5507,
      "step": 1000
    },
    {
      "epoch": 0.6637168141592921,
      "grad_norm": 4.801088333129883,
      "learning_rate": 1.3369152970922882e-05,
      "loss": 0.4726,
      "step": 1050
    },
    {
      "epoch": 0.695322376738306,
      "grad_norm": 5.5818190574646,
      "learning_rate": 1.3053097345132743e-05,
      "loss": 0.5271,
      "step": 1100
    },
    {
      "epoch": 0.7269279393173198,
      "grad_norm": 3.1232309341430664,
      "learning_rate": 1.2737041719342604e-05,
      "loss": 0.4855,
      "step": 1150
    },
    {
      "epoch": 0.7585335018963337,
      "grad_norm": 3.6141655445098877,
      "learning_rate": 1.2420986093552467e-05,
      "loss": 0.5335,
      "step": 1200
    },
    {
      "epoch": 0.7901390644753477,
      "grad_norm": 5.4986090660095215,
      "learning_rate": 1.2104930467762328e-05,
      "loss": 0.5256,
      "step": 1250
    },
    {
      "epoch": 0.8217446270543616,
      "grad_norm": 2.8241379261016846,
      "learning_rate": 1.1788874841972188e-05,
      "loss": 0.4423,
      "step": 1300
    },
    {
      "epoch": 0.8533501896333755,
      "grad_norm": 4.049173831939697,
      "learning_rate": 1.147281921618205e-05,
      "loss": 0.4911,
      "step": 1350
    },
    {
      "epoch": 0.8849557522123894,
      "grad_norm": 5.710687160491943,
      "learning_rate": 1.115676359039191e-05,
      "loss": 0.54,
      "step": 1400
    },
    {
      "epoch": 0.9165613147914032,
      "grad_norm": 4.804492473602295,
      "learning_rate": 1.0840707964601771e-05,
      "loss": 0.4832,
      "step": 1450
    },
    {
      "epoch": 0.9481668773704172,
      "grad_norm": 4.100094318389893,
      "learning_rate": 1.0524652338811632e-05,
      "loss": 0.5079,
      "step": 1500
    },
    {
      "epoch": 0.9797724399494311,
      "grad_norm": 8.308111190795898,
      "learning_rate": 1.0208596713021493e-05,
      "loss": 0.4259,
      "step": 1550
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7880512091038406,
      "eval_f1": 0.789097020806682,
      "eval_loss": 0.46504464745521545,
      "eval_precision": 0.8031410065174405,
      "eval_recall": 0.7880512091038406,
      "eval_runtime": 508.0376,
      "eval_samples_per_second": 12.454,
      "eval_steps_per_second": 0.779,
      "step": 1582
    },
    {
      "epoch": 1.011378002528445,
      "grad_norm": 5.576964378356934,
      "learning_rate": 9.892541087231354e-06,
      "loss": 0.4752,
      "step": 1600
    },
    {
      "epoch": 1.0429835651074588,
      "grad_norm": 3.692291498184204,
      "learning_rate": 9.576485461441215e-06,
      "loss": 0.4383,
      "step": 1650
    },
    {
      "epoch": 1.0745891276864727,
      "grad_norm": 7.344979763031006,
      "learning_rate": 9.260429835651075e-06,
      "loss": 0.4197,
      "step": 1700
    },
    {
      "epoch": 1.1061946902654867,
      "grad_norm": 3.456735372543335,
      "learning_rate": 8.944374209860936e-06,
      "loss": 0.3837,
      "step": 1750
    },
    {
      "epoch": 1.1378002528445006,
      "grad_norm": 3.851236343383789,
      "learning_rate": 8.628318584070797e-06,
      "loss": 0.4,
      "step": 1800
    },
    {
      "epoch": 1.1694058154235145,
      "grad_norm": 9.990242958068848,
      "learning_rate": 8.312262958280658e-06,
      "loss": 0.3745,
      "step": 1850
    },
    {
      "epoch": 1.2010113780025284,
      "grad_norm": 4.976701736450195,
      "learning_rate": 7.996207332490519e-06,
      "loss": 0.4403,
      "step": 1900
    },
    {
      "epoch": 1.2326169405815424,
      "grad_norm": 3.6492066383361816,
      "learning_rate": 7.68015170670038e-06,
      "loss": 0.4647,
      "step": 1950
    },
    {
      "epoch": 1.2642225031605563,
      "grad_norm": 5.116751670837402,
      "learning_rate": 7.364096080910242e-06,
      "loss": 0.4199,
      "step": 2000
    },
    {
      "epoch": 1.2958280657395702,
      "grad_norm": 4.477524757385254,
      "learning_rate": 7.048040455120102e-06,
      "loss": 0.399,
      "step": 2050
    },
    {
      "epoch": 1.3274336283185841,
      "grad_norm": 9.011500358581543,
      "learning_rate": 6.7319848293299625e-06,
      "loss": 0.4448,
      "step": 2100
    },
    {
      "epoch": 1.359039190897598,
      "grad_norm": 4.119734764099121,
      "learning_rate": 6.415929203539823e-06,
      "loss": 0.414,
      "step": 2150
    },
    {
      "epoch": 1.3906447534766118,
      "grad_norm": 6.815087795257568,
      "learning_rate": 6.099873577749684e-06,
      "loss": 0.4141,
      "step": 2200
    },
    {
      "epoch": 1.4222503160556257,
      "grad_norm": 4.297639846801758,
      "learning_rate": 5.783817951959545e-06,
      "loss": 0.3824,
      "step": 2250
    },
    {
      "epoch": 1.4538558786346396,
      "grad_norm": 2.381816864013672,
      "learning_rate": 5.467762326169406e-06,
      "loss": 0.4102,
      "step": 2300
    },
    {
      "epoch": 1.4854614412136535,
      "grad_norm": 4.906128883361816,
      "learning_rate": 5.151706700379268e-06,
      "loss": 0.415,
      "step": 2350
    },
    {
      "epoch": 1.5170670037926675,
      "grad_norm": 6.009297847747803,
      "learning_rate": 4.835651074589129e-06,
      "loss": 0.4063,
      "step": 2400
    },
    {
      "epoch": 1.5486725663716814,
      "grad_norm": 9.579477310180664,
      "learning_rate": 4.519595448798989e-06,
      "loss": 0.4285,
      "step": 2450
    },
    {
      "epoch": 1.5802781289506953,
      "grad_norm": 7.36244535446167,
      "learning_rate": 4.20353982300885e-06,
      "loss": 0.4107,
      "step": 2500
    },
    {
      "epoch": 1.6118836915297092,
      "grad_norm": 5.12728214263916,
      "learning_rate": 3.887484197218711e-06,
      "loss": 0.3938,
      "step": 2550
    },
    {
      "epoch": 1.6434892541087232,
      "grad_norm": 9.230927467346191,
      "learning_rate": 3.5714285714285718e-06,
      "loss": 0.4433,
      "step": 2600
    },
    {
      "epoch": 1.675094816687737,
      "grad_norm": 6.487568378448486,
      "learning_rate": 3.2553729456384327e-06,
      "loss": 0.4191,
      "step": 2650
    },
    {
      "epoch": 1.706700379266751,
      "grad_norm": 5.36141300201416,
      "learning_rate": 2.939317319848293e-06,
      "loss": 0.3849,
      "step": 2700
    },
    {
      "epoch": 1.738305941845765,
      "grad_norm": 4.556318283081055,
      "learning_rate": 2.6232616940581544e-06,
      "loss": 0.4473,
      "step": 2750
    },
    {
      "epoch": 1.7699115044247788,
      "grad_norm": 6.984165191650391,
      "learning_rate": 2.3072060682680153e-06,
      "loss": 0.389,
      "step": 2800
    },
    {
      "epoch": 1.8015170670037928,
      "grad_norm": 4.923966407775879,
      "learning_rate": 1.991150442477876e-06,
      "loss": 0.3785,
      "step": 2850
    },
    {
      "epoch": 1.8331226295828067,
      "grad_norm": 8.120641708374023,
      "learning_rate": 1.675094816687737e-06,
      "loss": 0.4138,
      "step": 2900
    },
    {
      "epoch": 1.8647281921618206,
      "grad_norm": 10.56281852722168,
      "learning_rate": 1.359039190897598e-06,
      "loss": 0.4295,
      "step": 2950
    },
    {
      "epoch": 1.8963337547408345,
      "grad_norm": 4.6496100425720215,
      "learning_rate": 1.0429835651074588e-06,
      "loss": 0.4587,
      "step": 3000
    },
    {
      "epoch": 1.9279393173198482,
      "grad_norm": 3.546081066131592,
      "learning_rate": 7.269279393173199e-07,
      "loss": 0.3794,
      "step": 3050
    },
    {
      "epoch": 1.9595448798988622,
      "grad_norm": 5.175647735595703,
      "learning_rate": 4.108723135271808e-07,
      "loss": 0.4154,
      "step": 3100
    },
    {
      "epoch": 1.991150442477876,
      "grad_norm": 6.454444885253906,
      "learning_rate": 9.481668773704173e-08,
      "loss": 0.4058,
      "step": 3150
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8065433854907539,
      "eval_f1": 0.8073234999560651,
      "eval_loss": 0.43710798025131226,
      "eval_precision": 0.8098402406524676,
      "eval_recall": 0.8065433854907539,
      "eval_runtime": 514.8486,
      "eval_samples_per_second": 12.289,
      "eval_steps_per_second": 0.769,
      "step": 3164
    }
  ],
  "logging_steps": 50,
  "max_steps": 3164,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3352604498804736.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
