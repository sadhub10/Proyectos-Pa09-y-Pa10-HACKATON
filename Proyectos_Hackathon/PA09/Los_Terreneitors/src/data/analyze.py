"""
Script de An√°lisis Exploratorio del Dataset de Salud Mental
Analiza todas las categor√≠as disponibles y sus caracter√≠sticas
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de visualizaci√≥n
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (14, 8)

# ================================
# CARGAR DATASET
# ================================
print("="*70)
print("üîç AN√ÅLISIS EXPLORATORIO DEL DATASET DE SALUD MENTAL")
print("="*70)

# Ruta del dataset
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parents[2]  # sube 2 niveles al root del proyecto
DATASET_PATH = BASE_DIR / "data" / "raw" / "mental_health_dataset.csv"

try:
    df = pd.read_csv(DATASET_PATH)
    print(f"\n‚úÖ Dataset cargado correctamente")
    print(f"üì¶ Dimensiones: {df.shape[0]} filas x {df.shape[1]} columnas")
except FileNotFoundError:
    print(f"\n‚ùå Error: No se encontr√≥ el archivo en '{DATASET_PATH}'")
    print("Por favor, verifica la ruta del dataset.")
    exit()

# ================================
# 1. INFORMACI√ìN GENERAL
# ================================
print("\n" + "="*70)
print("üìã 1. INFORMACI√ìN GENERAL DEL DATASET")
print("="*70)

print(f"\nüìä Columnas disponibles:")
for i, col in enumerate(df.columns, 1):
    print(f"  {i}. {col} (tipo: {df[col].dtype})")

print(f"\nüî¢ Tipos de datos:")
print(df.dtypes)

print(f"\n‚ùì Valores nulos por columna:")
null_counts = df.isnull().sum()
null_percentages = (df.isnull().sum() / len(df) * 100).round(2)
null_df = pd.DataFrame({
    'Columna': null_counts.index,
    'Nulos': null_counts.values,
    'Porcentaje': null_percentages.values
})
print(null_df.to_string(index=False))

print(f"\nüìè Estad√≠sticas de filas:")
print(f"  Total de filas: {len(df)}")
print(f"  Filas completas (sin nulos): {df.dropna().shape[0]}")
print(f"  Filas con al menos un nulo: {df.isnull().any(axis=1).sum()}")

# ================================
# 2. IDENTIFICAR COLUMNA DE ETIQUETAS
# ================================
print("\n" + "="*70)
print("üè∑Ô∏è 2. AN√ÅLISIS DE ETIQUETAS/CATEGOR√çAS")
print("="*70)

# Identificar la columna de etiquetas
label_col = None
possible_names = ['status', 'label', 'category', 'class', 'emotion', 'sentiment']

for col in df.columns:
    if col.lower() in possible_names:
        label_col = col
        break

if label_col is None:
    # Mostrar primeras filas para identificar manualmente
    print("\n‚ö†Ô∏è No se identific√≥ autom√°ticamente la columna de etiquetas.")
    print("\nüëÄ Primeras 5 filas del dataset:")
    print(df.head())

    print("\nüîç Por favor, indica cu√°l es la columna de etiquetas:")
    for i, col in enumerate(df.columns, 1):
        print(f"  {i}. {col}")
    exit()

print(f"\n‚úÖ Columna de etiquetas identificada: '{label_col}'")

# ================================
# 3. DISTRIBUCI√ìN DE CATEGOR√çAS
# ================================
print("\n" + "="*70)
print("üìä 3. DISTRIBUCI√ìN DE TODAS LAS CATEGOR√çAS")
print("="*70)

# Contar categor√≠as
category_counts = df[label_col].value_counts()
category_percentages = (df[label_col].value_counts(normalize=True) * 100).round(2)

print(f"\nüìà Total de categor√≠as √∫nicas: {df[label_col].nunique()}")
print(f"\nüè∑Ô∏è Categor√≠as encontradas:\n")

# Crear tabla resumen
summary_df = pd.DataFrame({
    'Categor√≠a': category_counts.index,
    'Cantidad': category_counts.values,
    'Porcentaje': category_percentages.values
})
print(summary_df.to_string(index=False))

# Visualizaci√≥n 1: Gr√°fico de barras
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Subplot 1: Conteo de categor√≠as
ax1 = axes[0, 0]
category_counts.plot(kind='bar', ax=ax1, color='steelblue', edgecolor='black')
ax1.set_title('Distribuci√≥n de Categor√≠as (Conteo)', fontsize=14, fontweight='bold')
ax1.set_xlabel('Categor√≠a', fontsize=12)
ax1.set_ylabel('Cantidad de Muestras', fontsize=12)
ax1.tick_params(axis='x', rotation=45)
ax1.grid(axis='y', alpha=0.3)

# Agregar valores en las barras
for i, v in enumerate(category_counts.values):
    ax1.text(i, v + 50, str(v), ha='center', va='bottom', fontweight='bold')

# Subplot 2: Porcentajes
ax2 = axes[0, 1]
category_percentages.plot(kind='bar', ax=ax2, color='coral', edgecolor='black')
ax2.set_title('Distribuci√≥n de Categor√≠as (Porcentaje)', fontsize=14, fontweight='bold')
ax2.set_xlabel('Categor√≠a', fontsize=12)
ax2.set_ylabel('Porcentaje (%)', fontsize=12)
ax2.tick_params(axis='x', rotation=45)
ax2.grid(axis='y', alpha=0.3)

# Agregar valores en las barras
for i, v in enumerate(category_percentages.values):
    ax2.text(i, v + 1, f'{v}%', ha='center', va='bottom', fontweight='bold')

# Subplot 3: Pie chart
ax3 = axes[1, 0]
colors = plt.cm.Set3(range(len(category_counts)))
wedges, texts, autotexts = ax3.pie(
    category_counts.values,
    labels=category_counts.index,
    autopct='%1.1f%%',
    colors=colors,
    startangle=90
)
ax3.set_title('Distribuci√≥n de Categor√≠as (Torta)', fontsize=14, fontweight='bold')

# Subplot 4: An√°lisis de balance
ax4 = axes[1, 1]
balance_data = pd.DataFrame({
    'Categor√≠a': category_counts.index,
    'Muestras': category_counts.values
})
balance_data['Balance'] = balance_data['Muestras'] / balance_data['Muestras'].max()
colors_balance = ['green' if x > 0.5 else 'orange' if x > 0.2 else 'red' for x in balance_data['Balance']]
ax4.barh(balance_data['Categor√≠a'], balance_data['Balance'], color=colors_balance, edgecolor='black')
ax4.set_title('Balance de Clases (normalizado)', fontsize=14, fontweight='bold')
ax4.set_xlabel('Proporci√≥n relativa al m√°ximo', fontsize=12)
ax4.axvline(x=0.5, color='orange', linestyle='--', linewidth=2, label='50% del m√°ximo')
ax4.axvline(x=0.2, color='red', linestyle='--', linewidth=2, label='20% del m√°ximo')
ax4.legend()
ax4.grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.savefig('dataset_analysis.png', dpi=300, bbox_inches='tight')
print(f"\nüíæ Gr√°fico guardado como 'dataset_analysis.png'")
plt.show()

# ================================
# 4. AN√ÅLISIS DE DESBALANCE
# ================================
print("\n" + "="*70)
print("‚öñÔ∏è 4. AN√ÅLISIS DE BALANCE DE CLASES")
print("="*70)

max_samples = category_counts.max()
min_samples = category_counts.min()
ratio = max_samples / min_samples

print(f"\nüìä Estad√≠sticas de balance:")
print(f"  Clase con m√°s muestras:  {category_counts.idxmax()} ({max_samples} muestras)")
print(f"  Clase con menos muestras: {category_counts.idxmin()} ({min_samples} muestras)")
print(f"  Ratio m√°ximo/m√≠nimo: {ratio:.2f}:1")

if ratio > 10:
    print(f"\n‚ö†Ô∏è ALTO DESBALANCE detectado (ratio > 10:1)")
    print(f"   Recomendaci√≥n: Considerar t√©cnicas de balanceo (SMOTE, undersampling, etc.)")
elif ratio > 3:
    print(f"\n‚ö° DESBALANCE MODERADO detectado (ratio > 3:1)")
    print(f"   Recomendaci√≥n: Usar class_weight='balanced' en el modelo")
else:
    print(f"\n‚úÖ Dataset relativamente balanceado")

# Identificar clases minoritarias (< 20% del m√°ximo)
minority_threshold = max_samples * 0.2
minority_classes = category_counts[category_counts < minority_threshold]

if len(minority_classes) > 0:
    print(f"\n‚ö†Ô∏è Clases minoritarias (< 20% del m√°ximo):")
    for cat, count in minority_classes.items():
        print(f"  - {cat}: {count} muestras ({count/max_samples*100:.1f}% del m√°ximo)")

# ================================
# 5. AN√ÅLISIS DE TEXTOS
# ================================
print("\n" + "="*70)
print("üìù 5. AN√ÅLISIS DE TEXTOS")
print("="*70)

# Identificar columna de texto
text_col = None
possible_text_names = ['text', 'statement', 'message', 'content', 'description']

for col in df.columns:
    if col.lower() in possible_text_names:
        text_col = col
        break

if text_col:
    print(f"\n‚úÖ Columna de texto identificada: '{text_col}'")

    # Calcular longitudes
    df['text_length'] = df[text_col].astype(str).apply(len)
    df['word_count'] = df[text_col].astype(str).apply(lambda x: len(x.split()))

    print(f"\nüìè Estad√≠sticas de longitud de textos:")
    print(f"  Longitud promedio (caracteres): {df['text_length'].mean():.1f}")
    print(f"  Longitud m√≠nima: {df['text_length'].min()}")
    print(f"  Longitud m√°xima: {df['text_length'].max()}")
    print(f"  Mediana: {df['text_length'].median():.1f}")

    print(f"\nüìù Estad√≠sticas de palabras:")
    print(f"  Palabras promedio por texto: {df['word_count'].mean():.1f}")
    print(f"  Palabras m√≠nimas: {df['word_count'].min()}")
    print(f"  Palabras m√°ximas: {df['word_count'].max()}")
    print(f"  Mediana: {df['word_count'].median():.1f}")

    # Longitudes por categor√≠a
    print(f"\nüìä Longitud promedio por categor√≠a:")
    length_by_category = df.groupby(label_col)['text_length'].mean().sort_values(ascending=False)
    for cat, length in length_by_category.items():
        print(f"  {cat:25s}: {length:.1f} caracteres")

    # Visualizaci√≥n de longitudes
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # Histograma general
    ax1 = axes[0]
    ax1.hist(df['text_length'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)
    ax1.set_title('Distribuci√≥n de Longitud de Textos', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Longitud (caracteres)', fontsize=12)
    ax1.set_ylabel('Frecuencia', fontsize=12)
    ax1.axvline(df['text_length'].mean(), color='red', linestyle='--', linewidth=2, label=f'Media: {df["text_length"].mean():.1f}')
    ax1.axvline(df['text_length'].median(), color='green', linestyle='--', linewidth=2, label=f'Mediana: {df["text_length"].median():.1f}')
    ax1.legend()
    ax1.grid(axis='y', alpha=0.3)

    # Boxplot por categor√≠a
    ax2 = axes[1]
    df.boxplot(column='text_length', by=label_col, ax=ax2)
    ax2.set_title('Longitud de Textos por Categor√≠a', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Categor√≠a', fontsize=12)
    ax2.set_ylabel('Longitud (caracteres)', fontsize=12)
    ax2.tick_params(axis='x', rotation=45)
    plt.suptitle('')  # Remover t√≠tulo autom√°tico

    plt.tight_layout()
    plt.savefig('text_length_analysis.png', dpi=300, bbox_inches='tight')
    print(f"\nüíæ Gr√°fico de longitudes guardado como 'text_length_analysis.png'")
    plt.show()

    # Ejemplos de cada categor√≠a
    print(f"\n" + "="*70)
    print("üìñ EJEMPLOS DE TEXTOS POR CATEGOR√çA (primeros 2 de cada una)")
    print("="*70)

    for category in category_counts.index[:10]:  # Mostrar solo primeras 10 categor√≠as
        print(f"\nüè∑Ô∏è {category}:")
        examples = df[df[label_col] == category][text_col].head(2)
        for i, text in enumerate(examples, 1):
            text_preview = str(text)[:150] + "..." if len(str(text)) > 150 else str(text)
            print(f"  {i}. {text_preview}")

else:
    print(f"\n‚ö†Ô∏è No se pudo identificar autom√°ticamente la columna de texto")

# ================================
# 6. RECOMENDACIONES
# ================================
print("\n" + "="*70)
print("üí° 6. RECOMENDACIONES PARA EL PROYECTO")
print("="*70)

print(f"\nüìã Resumen de categor√≠as encontradas:")
print(f"  Total: {len(category_counts)} categor√≠as")
for i, (cat, count) in enumerate(category_counts.items(), 1):
    print(f"  {i}. {cat:25s} - {count:5d} muestras ({count/len(df)*100:5.2f}%)")

print(f"\nüéØ Opciones para tu proyecto:")

# Categor√≠as negativas
negative_categories = []
positive_categories = []
neutral_categories = []

for cat in category_counts.index:
    cat_lower = cat.lower()
    if any(word in cat_lower for word in ['anxiety', 'depression', 'stress', 'suicidal', 'bipolar', 'personality']):
        negative_categories.append(cat)
    elif any(word in cat_lower for word in ['normal', 'healthy', 'positive']):
        positive_categories.append(cat)
    else:
        neutral_categories.append(cat)

print(f"\nüî¥ Categor√≠as NEGATIVAS detectadas ({len(negative_categories)}):")
for cat in negative_categories:
    print(f"  - {cat} ({category_counts[cat]} muestras)")

print(f"\nüü¢ Categor√≠as POSITIVAS/NORMALES detectadas ({len(positive_categories)}):")
for cat in positive_categories:
    print(f"  - {cat} ({category_counts[cat]} muestras)")

if len(neutral_categories) > 0:
    print(f"\nüü° Otras categor√≠as ({len(neutral_categories)}):")
    for cat in neutral_categories:
        print(f"  - {cat} ({category_counts[cat]} muestras)")

print(f"\nüìå SUGERENCIAS:")
print(f"\n  Opci√≥n 1Ô∏è‚É£ - Solo estados negativos (proyecto original):")
print(f"    Mantener: {', '.join(negative_categories[:4])}")
total_negative = sum(category_counts[cat] for cat in negative_categories[:4] if cat in category_counts)
print(f"    Total de muestras: {total_negative}")

print(f"\n  Opci√≥n 2Ô∏è‚É£ - Incluir estados positivos (RECOMENDADO para balance):")
neg_list = negative_categories[:4] if len(negative_categories) >= 4 else negative_categories
pos_list = positive_categories[:1] if len(positive_categories) >= 1 else []
print(f"    Mantener: {', '.join(neg_list + pos_list)}")
total_balanced = sum(category_counts[cat] for cat in (neg_list + pos_list) if cat in category_counts)
print(f"    Total de muestras: {total_balanced}")
print(f"    Ventaja: Modelo m√°s robusto que distingue entre estados problem√°ticos y normales")

print(f"\n  Opci√≥n 3Ô∏è‚É£ - Binario (Normal vs Problemas):")
print(f"    Clase 1: Normal/Healthy")
print(f"    Clase 2: Cualquier condici√≥n negativa")
print(f"    Ventaja: Simplicidad, bueno para screening inicial")

# ================================
# 7. GUARDAR AN√ÅLISIS
# ================================
print(f"\n" + "="*70)
print("üíæ GUARDANDO AN√ÅLISIS")
print("="*70)

# Guardar CSV con resumen
summary_df.to_csv('dataset_categories_summary.csv', index=False)
print(f"\n‚úÖ Resumen guardado en 'dataset_categories_summary.csv'")

# Guardar reporte completo
with open('dataset_analysis_report.txt', 'w', encoding='utf-8') as f:
    f.write("="*70 + "\n")
    f.write("AN√ÅLISIS COMPLETO DEL DATASET DE SALUD MENTAL\n")
    f.write("="*70 + "\n\n")
    f.write(f"Fecha: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write(f"Dataset: {DATASET_PATH}\n")
    f.write(f"Total de muestras: {len(df)}\n")
    f.write(f"Total de categor√≠as: {len(category_counts)}\n\n")
    f.write("DISTRIBUCI√ìN DE CATEGOR√çAS:\n")
    f.write(summary_df.to_string(index=False))
    f.write("\n\n")
    f.write("CATEGOR√çAS NEGATIVAS:\n")
    for cat in negative_categories:
        f.write(f"  - {cat} ({category_counts[cat]} muestras)\n")
    f.write("\n")
    f.write("CATEGOR√çAS POSITIVAS/NORMALES:\n")
    for cat in positive_categories:
        f.write(f"  - {cat} ({category_counts[cat]} muestras)\n")

print(f"‚úÖ Reporte completo guardado en 'dataset_analysis_report.txt'")

print(f"\n" + "="*70)
print("üéâ AN√ÅLISIS COMPLETADO")
print("="*70)
print(f"\nüìä Revisa los archivos generados:")
print(f"  1. dataset_analysis.png")
print(f"  2. text_length_analysis.png")
print(f"  3. dataset_categories_summary.csv")
print(f"  4. dataset_analysis_report.txt")
print(f"\nüí° Siguiente paso: Decide qu√© categor√≠as mantener y ejecuta clean_and_filter_dataset.py")